{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "FkeOj19M7Kqc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "v6SfBi-j5EXv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/medium_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "JNf2FtEe74O4",
        "outputId": "6edb2e63-0c0c-4cee-fc58-c31da7ac5fac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                url  \\\n",
              "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
              "1   2  https://towardsdatascience.com/hands-on-graph-...   \n",
              "2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n",
              "3   4  https://towardsdatascience.com/databricks-how-...   \n",
              "4   5  https://towardsdatascience.com/a-step-by-step-...   \n",
              "\n",
              "                                               title  \\\n",
              "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
              "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
              "2                       How to Use ggplot2 in Python   \n",
              "3  Databricks: How to Save Files in CSV on Your L...   \n",
              "4  A Step-by-Step Implementation of Gradient Desc...   \n",
              "\n",
              "                                  subtitle   image  claps responses  \\\n",
              "0                                      NaN   1.png    850         8   \n",
              "1                                      NaN   2.png   1100        11   \n",
              "2         A Grammar of Graphics for Python   3.png    767         1   \n",
              "3  When I work on Python projects dealing…  4.jpeg    354         0   \n",
              "4          One example of building neural…  5.jpeg    211         3   \n",
              "\n",
              "   reading_time           publication        date  \\\n",
              "0             8  Towards Data Science  2019-05-30   \n",
              "1             9  Towards Data Science  2019-05-30   \n",
              "2             5  Towards Data Science  2019-05-30   \n",
              "3             4  Towards Data Science  2019-05-30   \n",
              "4             4  Towards Data Science  2019-05-30   \n",
              "\n",
              "                                                text  \n",
              "0  A Beginner’s Guide to Word Embedding with Gens...  \n",
              "1  Hands-on Graph Neural Networks with PyTorch & ...  \n",
              "2  How to Use ggplot2 in Python A Grammar of Grap...  \n",
              "3  Databricks: How to Save Files in CSV on Your L...  \n",
              "4  A Step-by-Step Implementation of Gradient Desc...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7912c52d-8f72-4384-b458-17e03ff6ed9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>image</th>\n",
              "      <th>claps</th>\n",
              "      <th>responses</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>publication</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
              "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.png</td>\n",
              "      <td>850</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n",
              "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.png</td>\n",
              "      <td>1100</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n",
              "      <td>How to Use ggplot2 in Python</td>\n",
              "      <td>A Grammar of Graphics for Python</td>\n",
              "      <td>3.png</td>\n",
              "      <td>767</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>How to Use ggplot2 in Python A Grammar of Grap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>https://towardsdatascience.com/databricks-how-...</td>\n",
              "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
              "      <td>When I work on Python projects dealing…</td>\n",
              "      <td>4.jpeg</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n",
              "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
              "      <td>One example of building neural…</td>\n",
              "      <td>5.jpeg</td>\n",
              "      <td>211</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Towards Data Science</td>\n",
              "      <td>2019-05-30</td>\n",
              "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7912c52d-8f72-4384-b458-17e03ff6ed9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7912c52d-8f72-4384-b458-17e03ff6ed9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7912c52d-8f72-4384-b458-17e03ff6ed9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6508,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1878,\n        \"min\": 1,\n        \"max\": 6508,\n        \"num_unique_values\": 6508,\n        \"samples\": [\n          3394,\n          5382,\n          4817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6508,\n        \"samples\": [\n          \"https://uxdesign.cc/why-agile-doesnt-work-30f8384ef60a\",\n          \"https://medium.com/swlh/how-i-became-obsessed-with-reading-816b9e4b91aa\",\n          \"https://medium.com/better-marketing/elevate-marketing-with-lessons-from-the-peloton-wife-ad-fiasco-671a4a3b72c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6504,\n        \"samples\": [\n          \"Forget APIs Do Python Scraping Using Beautiful Soup, Import Data File from the web: Part\\u00a02\",\n          \"DDI\\u200a\\u2014\\u200aWeekly Selection September 18,\\u00a02019\",\n          \"Don\\u2019t ask yourself \\u2018what\\u2019 to write. It\\u2019s the wrong\\u00a0question\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtitle\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3470,\n        \"samples\": [\n          \"Practical writing and editing process tips for working\\u00a0people.\",\n          \"two visionary ideas I\\u2019d like to see AI be able to achieve one\\u00a0day.\",\n          \"Full tutorial using different libraries\\u200a\\u2014\\u200aTesseractOCRiOS, SwiftOCR, and Google MLVision | Can we beat\\u00a0Google?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6361,\n        \"samples\": [\n          \"4853.jpeg\",\n          \"4938.jpg\",\n          \"481.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"claps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 950,\n        \"min\": 0,\n        \"max\": 38000,\n        \"num_unique_values\": 854,\n        \"samples\": [\n          92,\n          385,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responses\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"8\",\n          \"2\",\n          \"48\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reading_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 55,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          22,\n          15,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publication\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Towards Data Science\",\n          \"UX Collective\",\n          \"Better Marketing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"2019-10-28\",\n          \"2019-06-04\",\n          \"2019-05-24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6506,\n        \"samples\": [\n          \"Three ways learning UX helped me level up as a\\u00a0designer \",\n          \"Do You Have Financial Frenemies? If you\\u2019re unhappy with money, you probably\\u00a0do\",\n          \"How To Make Your Customer the Hero of Your Brand\\u2019s\\u00a0Story The 7-part StoryBrand framework that\\u00a0will\\u2026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"subtitle\"].fillna(\"\") # Combine title and subtitle to create a new 'text' column, handling missing values"
      ],
      "metadata": {
        "id": "WyYd6wQJ7gK0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text) # Remove special characters and numbers\n",
        "  return text\n",
        "\n",
        "texts = df[\"text\"].apply(clean_text).tolist()"
      ],
      "metadata": {
        "id": "fY41hIrb7nRw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "for text in texts:\n",
        "  tokens.extend(text.split()) # Tokenize text into words\n",
        "\n",
        "vocab = sorted(set(tokens))\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)} # Map words to unique integer indices\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()} # Map integer indices back to words\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocabulary size: \", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD98krmf76Q6",
        "outputId": "afc5d4db-4a7b-4c01-a250-c85fd5d3a46f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size:  10422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 5 # Length of input sequences for the model\n",
        "\n",
        "input_sequences = []\n",
        "target_words = []\n",
        "\n",
        "for text in texts:\n",
        "  words = text.split()\n",
        "  for i in range(len(words) - SEQ_LENGTH):\n",
        "    input_sequences.append(words[i:i+SEQ_LENGTH]) # Creating input sequences of SEQ_LENGTH\n",
        "    target_words.append(words[i+SEQ_LENGTH]) # The word immediately following the sequence is the target"
      ],
      "metadata": {
        "id": "3cKq3eZU8bB_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [[word_to_idx[w] for w in seq] for seq in input_sequences] # Converting input sequences to numerical indices\n",
        "y = [word_to_idx[w] for w in target_words] # Converting target words to numerical indices\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "print(\"X shape: \", X.shape)\n",
        "print(\"y shape: \", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZWNGtt68_Ji",
        "outputId": "ec16e418-0c09-4f50-f404-1d6809f8f628"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  torch.Size([46700, 5])\n",
            "y shape:  torch.Size([46700])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx] # Return a sample (input sequence, target word)\n",
        "\n",
        "\n",
        "dataset = TextDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "h80QoDgq9ERb"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NextWordLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :] # Get the output from the last time step\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "gfTs1D3Y9Gji"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embed_dim = 200  # Dimension of word embeddings\n",
        "hidden_dim = 256 # Number of units in the LSTM hidden state\n",
        "num_layers = 2   # Number of LSTM layers\n",
        "dropout_rate = 0.3 # Dropout rate for regularization\n",
        "\n",
        "model = NextWordLSTM(vocab_size=vocab_size, embed_dim=embed_dim, hidden_dim=hidden_dim, num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # Loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer to update weights and minimize loss during training"
      ],
      "metadata": {
        "id": "hOAjU4Tn9Knj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 70\n",
        "torch.set_grad_enabled(True)\n",
        "model.train()\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "patience = 3   # number of epochs to wait\n",
        "wait = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"!! Early stopping triggered !!\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv63wVilWbZG",
        "outputId": "3d7a6e66-fad9-4e1d-c5f7-8d75aa7e3b80"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70, Avg Loss: 7.2145\n",
            "Epoch 2/70, Avg Loss: 6.3853\n",
            "Epoch 3/70, Avg Loss: 5.8129\n",
            "Epoch 4/70, Avg Loss: 5.2285\n",
            "Epoch 5/70, Avg Loss: 4.6155\n",
            "Epoch 6/70, Avg Loss: 4.0005\n",
            "Epoch 7/70, Avg Loss: 3.4180\n",
            "Epoch 8/70, Avg Loss: 2.8881\n",
            "Epoch 9/70, Avg Loss: 2.4303\n",
            "Epoch 10/70, Avg Loss: 2.0493\n",
            "Epoch 11/70, Avg Loss: 1.7291\n",
            "Epoch 12/70, Avg Loss: 1.4500\n",
            "Epoch 13/70, Avg Loss: 1.2257\n",
            "Epoch 14/70, Avg Loss: 1.0373\n",
            "Epoch 15/70, Avg Loss: 0.8775\n",
            "Epoch 16/70, Avg Loss: 0.7514\n",
            "Epoch 17/70, Avg Loss: 0.6451\n",
            "Epoch 18/70, Avg Loss: 0.5561\n",
            "Epoch 19/70, Avg Loss: 0.4869\n",
            "Epoch 20/70, Avg Loss: 0.4240\n",
            "Epoch 21/70, Avg Loss: 0.3881\n",
            "Epoch 22/70, Avg Loss: 0.3506\n",
            "Epoch 23/70, Avg Loss: 0.3146\n",
            "Epoch 24/70, Avg Loss: 0.2964\n",
            "Epoch 25/70, Avg Loss: 0.2809\n",
            "Epoch 26/70, Avg Loss: 0.2658\n",
            "Epoch 27/70, Avg Loss: 0.2531\n",
            "Epoch 28/70, Avg Loss: 0.2360\n",
            "Epoch 29/70, Avg Loss: 0.2303\n",
            "Epoch 30/70, Avg Loss: 0.2136\n",
            "Epoch 31/70, Avg Loss: 0.2193\n",
            "Epoch 32/70, Avg Loss: 0.2056\n",
            "Epoch 33/70, Avg Loss: 0.1976\n",
            "Epoch 34/70, Avg Loss: 0.1940\n",
            "Epoch 35/70, Avg Loss: 0.1913\n",
            "Epoch 36/70, Avg Loss: 0.1933\n",
            "Epoch 37/70, Avg Loss: 0.1803\n",
            "Epoch 38/70, Avg Loss: 0.1818\n",
            "Epoch 39/70, Avg Loss: 0.1815\n",
            "Epoch 40/70, Avg Loss: 0.1698\n",
            "Epoch 41/70, Avg Loss: 0.1718\n",
            "Epoch 42/70, Avg Loss: 0.1706\n",
            "Epoch 43/70, Avg Loss: 0.1731\n",
            "!! Early stopping triggered !!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, text, top_k=3):\n",
        "    model.eval()\n",
        "    words = clean_text(text).split()[-SEQ_LENGTH:] # Clean and get the last SEQ_LENGTH words from input text\n",
        "    words = [word_to_idx[w] for w in words if w in word_to_idx] # Converting words to indices, only if present in vocab\n",
        "\n",
        "    if len(words) < SEQ_LENGTH:\n",
        "        return \"Not enough words\" # Handle cases where input text is too short\n",
        "\n",
        "    x = torch.tensor([words], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(x) # Get model output (logits)\n",
        "        probs = torch.softmax(output, dim=1) # Convert logits to probabilities\n",
        "        top = torch.topk(probs, top_k) # Get the top K predicted words and their probabilities\n",
        "\n",
        "    return [idx_to_word[idx.item()] for idx in top.indices[0]] # Return the actual words corresponding to the top K indices"
      ],
      "metadata": {
        "id": "CZTQ3TiP-iUF"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "text = \"a beginners guide to word embedding\"\n",
        "\n",
        "print(\"\\n Live generation preview:\\n\")\n",
        "\n",
        "for _ in tqdm(range(10), desc=\"Predicting next words\", ncols=80): # Loop 1 for repeating the next-word prediction process 10 times\n",
        "    preds = predict_next_word(model, text, top_k=1)\n",
        "\n",
        "    if preds == \"Not enough words\":\n",
        "        print(\"\\nNot enough words to continue.\")\n",
        "        break\n",
        "\n",
        "    next_word = preds[0] # Get the predicted next word\n",
        "    text += \" \" + next_word # Append the predicted word to the current text\n",
        "\n",
        "    time.sleep(0.3) # Small delay for visualization\n",
        "    print(f'\\n{text}') # Print the evolving text\n",
        "\n",
        "\n",
        "for _ in range(20): # Loop 2 for completing sentence\n",
        "    preds = predict_next_word(model, text, top_k=1) # Predict the next single word\n",
        "\n",
        "    if preds == \"Not enough words\":\n",
        "        break\n",
        "\n",
        "    next_word = preds[0] # Get the predicted next word\n",
        "    text += \" \" + next_word # Append the predicted word to the current text\n",
        "\n",
        "    if len(text.split()) > 30: # Stop if the generated text exceeds 30 words\n",
        "        break\n",
        "\n",
        "print(\"\\nFinal Output:\")\n",
        "print(text)"
      ],
      "metadata": {
        "id": "s2UeNlcHOx4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3bd1a63-dfd8-4a09-b7ca-725f5c5f72a6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Live generation preview:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting next words:  10%|██                   | 1/10 [00:00<00:02,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  20%|████▏                | 2/10 [00:00<00:02,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  30%|██████▎              | 3/10 [00:00<00:02,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  40%|████████▍            | 4/10 [00:01<00:01,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  50%|██████████▌          | 5/10 [00:01<00:01,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  60%|████████████▌        | 6/10 [00:01<00:01,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using machine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  70%|██████████████▋      | 7/10 [00:02<00:00,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using machine learning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  80%|████████████████▊    | 8/10 [00:02<00:00,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using machine learning ml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting next words:  90%|██████████████████▉  | 9/10 [00:02<00:00,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using machine learning ml and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting next words: 100%|████████████████████| 10/10 [00:03<00:00,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a beginners guide to word embedding with gensim wordvec model using machine learning ml and deep\n",
            "\n",
            "Final Output:\n",
            "a beginners guide to word embedding with gensim wordvec model using machine learning ml and deep learning dl dl and cause rights exploring included reinforcement learning algorithm rights jetson nvidia and\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}